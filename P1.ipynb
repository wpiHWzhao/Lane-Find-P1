{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "\n",
    "## Project: **Finding Lane Lines on the Road** \n",
    "***\n",
    "In this project, the lanes on the road are detacted using Canny Edge Dectection and Hough Transform line detection. Meanwhile, I also use HSL color space, grayscaling, color selection ,color selection and Gaussian smoothing to reduce noise in pictures and vedios. To achieve optimal performance, this detection code is with memory of lanes in previous frames so the result is smooth. The code is verified by pictures and vedios. The code has good performance in challenge vedio, which has curved lane and shadow on the ground. All picture results are in folder 'test_image_output'. Vedio outputs are in 'test_vedios_output'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example picture output:\n",
    "\n",
    "---\n",
    "\n",
    "<figure>\n",
    " <img src=\"test_images/solidWhiteRight.jpg\" width=\"380\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Original Image </p> \n",
    " </figcaption>\n",
    "</figure>\n",
    " <p></p> \n",
    "<figure>\n",
    " <img src=\"test_images_output/solidWhiteRight.png\" width=\"380\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Lane Detaction Result</p> \n",
    " </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy import stats\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image is: <class 'numpy.ndarray'> with dimensions: (540, 960, 3)\n"
     ]
    }
   ],
   "source": [
    "#reading in an image\n",
    "image_sWR = mpimg.imread('test_images/solidWhiteRight.jpg')\n",
    "\n",
    "#printing out some stats.\n",
    "print('This image is:', type(image_sWR), 'with dimensions:', image_sWR.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some important functions:\n",
    "\n",
    "`find_hough_lines` Seperate left lane and right lane  \n",
    "`linear_regression_left/linear_regression_right` Use linear regression to extrapolate lanes  \n",
    "`create_lane_list` Use deque to store previous lanes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane finding functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "def find_hough_lines(img,lines):\n",
    "    # Seperate left/right lanes\n",
    "    xl = []\n",
    "    yl = []\n",
    "    xr = []\n",
    "    yr = []\n",
    "    middel_x = img.shape[1]/2\n",
    "    \n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            if ((y2-y1)/(x2-x1))<0 and ((y2-y1)/(x2-x1))>-math.inf and x1<middel_x and x2<middel_x:\n",
    "                xl.append(x1)\n",
    "                xl.append(x2)\n",
    "                yl.append(y1)\n",
    "                yl.append(y2)\n",
    "\n",
    "            elif ((y2-y1)/(x2-x1))>0 and ((y2-y1)/(x2-x1))<math.inf and x1>middel_x and x2>middel_x:\n",
    "                xr.append(x1)\n",
    "                xr.append(x2)\n",
    "                yr.append(y1)\n",
    "                yr.append(y2)\n",
    "    \n",
    "    return xl, yl, xr, yr\n",
    "\n",
    "def linear_regression_left(xl,yl):\n",
    "    # Extrapolate left lane\n",
    "    slope_l, intercept_l, r_value_l, p_value_l, std_err = stats.linregress(xl, yl)\n",
    "    return slope_l, intercept_l\n",
    "\n",
    "def linear_regression_right(xr,yr):\n",
    "    # Extrapolate right lane\n",
    "    slope_r, intercept_r, r_value_r, p_value_r, std_err = stats.linregress(xr, yr)\n",
    "    return slope_r, intercept_r\n",
    "\n",
    "def create_lane_list():\n",
    "    # Use deque to store previous lanes\n",
    "    return deque(maxlen = 15)\n",
    "\n",
    "def left_lane_mean(left_lane_que):\n",
    "    # Derive mean parameters of left lane based on memory\n",
    "    if len(left_lane_que) == 0:\n",
    "        return 0,0\n",
    "    slope_l_mean , intercept_l_mean = np.mean(left_lane_que,axis=0)\n",
    "    return slope_l_mean, intercept_l_mean\n",
    "\n",
    "def right_lane_mean(right_lane_que):\n",
    "    # Derive mean parameters of right lane based on memory\n",
    "    if len(right_lane_que) == 0:\n",
    "        return 0,0\n",
    "    slope_r_mean , intercept_r_mean = np.mean(right_lane_que,axis=0)\n",
    "    return slope_r_mean, intercept_r_mean\n",
    "\n",
    "def left_lane_add(left_lane_que,slope_l, intercept_l):\n",
    "    # Add left lane to memory\n",
    "    left_lane_que.append([slope_l,intercept_l])\n",
    "    return left_lane_que\n",
    "\n",
    "def right_lane_add(right_lane_que,slope_r, intercept_r):\n",
    "    # Add right lane to memory\n",
    "    right_lane_que.append([slope_r,intercept_r])\n",
    "    return right_lane_que\n",
    "        \n",
    "\n",
    "def grayscale(img):\n",
    "    # Convert image to grayscale\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    #Applies the Canny transform\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    #Applies a Gaussian Noise kernel\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img):\n",
    "    # Defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    # Defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "    vertices = get_vertices_for_img(img)  \n",
    "    # Filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    # Returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image           \n",
    "\n",
    "def draw_lines(img, intercept_l, slope_l,intercept_r, slope_r, xl, xr,color=[255, 0, 0], thickness=10):\n",
    "    # Draw lines based on mean intercept and slope\n",
    "    max_y = img.shape[0]\n",
    "    yl_LR = []\n",
    "    yr_LR = []\n",
    "    for x in xl:\n",
    "        yl_LR.append(intercept_l+slope_l*x)\n",
    "    for x in xr:\n",
    "        yr_LR.append(intercept_r+slope_r*x)\n",
    "        \n",
    "    x_left_bottom = (max_y - intercept_l)/slope_l\n",
    "    x_right_bottom = (max_y - intercept_r)/slope_r\n",
    "    \n",
    "    cv2.line(img, (int(x_left_bottom), int(max_y)), (int(max(xl)), int(min(yl_LR))), color, thickness)\n",
    "    cv2.line(img, (int(x_right_bottom), int(max_y)), (int(min(xr)), int(min(yr_LR))), color, thickness)\n",
    "    \n",
    "    return img\n",
    "    \n",
    "    \n",
    "    \n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    # Derive Hough lines of the image, this would return the points on the edge\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    \n",
    "    return line_img, lines\n",
    "\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., γ=0.):\n",
    "    # Combine images with weights\n",
    "    return cv2.addWeighted(initial_img, α, img, β, γ)\n",
    "\n",
    "def isolate_yellow_hsl(img):\n",
    "    # Extract yellow color in the HSL color space. \n",
    "    # We are interested in the yellow lanes on the ground\n",
    "    low_threshold = np.array([15, 38, 115], dtype=np.uint8)\n",
    "    high_threshold = np.array([35, 204, 255], dtype=np.uint8)  \n",
    "    \n",
    "    yellow_mask = cv2.inRange(img, low_threshold, high_threshold)\n",
    "    \n",
    "    return yellow_mask\n",
    "                            \n",
    "\n",
    "\n",
    "def isolate_white_hsl(img):\n",
    "    # Extract white color in the HSL color space. \n",
    "    # We are interested in the white lanes on the ground\n",
    "    low_threshold = np.array([0, 200, 0], dtype=np.uint8)\n",
    "    high_threshold = np.array([180, 255, 255], dtype=np.uint8)  \n",
    "    \n",
    "    white_mask = cv2.inRange(img, low_threshold, high_threshold)\n",
    "    \n",
    "    return white_mask\n",
    "\n",
    "def get_vertices_for_img(img):\n",
    "    # Get the top points of polygon based on the size of image for function 'region_of_interest'\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "\n",
    "    \n",
    "    if (width, height) == (960, 540):\n",
    "        bottom_left = (130 ,img.shape[0] - 1)\n",
    "        top_left = (410, 330)\n",
    "        top_right = (650, 350)\n",
    "        bottom_right = (img.shape[1] - 30,img.shape[0] - 1)\n",
    "        vert = np.array([[bottom_left , top_left, top_right, bottom_right]], dtype=np.int32)\n",
    "    else:\n",
    "        bottom_left = (200 , 680)\n",
    "        top_left = (600, 450)\n",
    "        top_right = (750, 450)\n",
    "        bottom_right = (1100, 680)\n",
    "        vert = np.array([[bottom_left , top_left, top_right, bottom_right]], dtype=np.int32)\n",
    "    return vert        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Images\n",
    "\n",
    "Firstly, use images to test the lane detection piplane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Read in a image list\n",
    "test_img_dir = 'test_images/'\n",
    "test_image_names = os.listdir(\"test_images/\")\n",
    "test_image_names = list(map(lambda name: test_img_dir + name, test_image_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Lane Finding Pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the pipeline and run your solution on all test_images. Make copies into the `test_images_output` directory, and you can use the images in your writeup report.\n",
    "\n",
    "Try tuning the various parameters, especially the low and high Canny thresholds as well as the Hough lines parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in images\n",
    "image_wCLS = mpimg.imread('test_images/whiteCarLaneSwitch.jpg')\n",
    "image_sYL = mpimg.imread('test_images/solidYellowLeft.jpg')\n",
    "image_sYC2 = mpimg.imread('test_images/solidYellowCurve2.jpg')\n",
    "image_sYC = mpimg.imread('test_images/solidYellowCurve.jpg')\n",
    "image_sWC = mpimg.imread('test_images/solidWhiteCurve.jpg')\n",
    "image_ch = mpimg.imread('test_images/challenge.jpg')\n",
    "\n",
    "def Lane_Detect(image):\n",
    "    # Lane detection pipeline\n",
    "    image_hsl = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    image_yellow = isolate_yellow_hsl(image_hsl)\n",
    "    image_white = isolate_white_hsl(image_hsl)\n",
    "    # Combine white parts and yellow parts in a single pic\n",
    "    image_wy = cv2.bitwise_or(image_yellow,image_white)\n",
    "    # Combine yellow and white masks and original picture to derive the parts we are interested.\n",
    "    # This would reduce the noise and improve the performance if there is shadow on the ground.\n",
    "    image_com = cv2.bitwise_and(image,image,mask=image_wy)\n",
    "    image_gray = grayscale(image_com)\n",
    "    # Smoothing the image\n",
    "    kernal_size = 11\n",
    "    blur_image = cv2.GaussianBlur(image_gray,(kernal_size,kernal_size),0)\n",
    "    # Setup Canny\n",
    "    low_threshold = 10\n",
    "    high_threshold = 150\n",
    "    edges_image = cv2.Canny(blur_image,low_threshold,high_threshold)\n",
    "    # Define range of interest\n",
    "    masked_image = region_of_interest(edges_image) \n",
    "    \n",
    "    bland_image, houghLines= hough_lines(masked_image, 1, np.pi/180, 1, 5, 1)\n",
    "    xl,yl,xr,yr = find_hough_lines(bland_image,houghLines)\n",
    "    slope_l, intercept_l = linear_regression_left(xl,yl)\n",
    "    slope_r, intercept_r = linear_regression_right(xr,yr)\n",
    "    hough_image = draw_lines(bland_image, intercept_l, slope_l, intercept_r, slope_r, xl, xr)\n",
    "    Final_image = weighted_img(hough_image,image)  \n",
    "    return Final_image\n",
    "\n",
    "\n",
    "# Process images and save\n",
    "Final_wCLS = Lane_Detect(image_wCLS)\n",
    "plt.imsave('test_images_output/whiteCarLaneSwitch.png',Final_wCLS)\n",
    "Final_sWR = Lane_Detect(image_sWR)\n",
    "plt.imsave('test_images_output/solidWhiteRight.png',Final_sWR)\n",
    "Final_sYL = Lane_Detect(image_sYL)\n",
    "plt.imsave('test_images_output/solidYellowLeft.png',Final_sYL)\n",
    "Final_sYC2 = Lane_Detect(image_sYC2)\n",
    "plt.imsave('test_images_output/solidYellowCurve2.png',Final_sYC2)\n",
    "Final_sYC = Lane_Detect(image_sYC)\n",
    "plt.imsave('test_images_output/solidYellowCurve.png',Final_sYC)\n",
    "Final_sWC = Lane_Detect(image_sWC)\n",
    "plt.imsave('test_images_output/solidWhiteCurve.png',Final_sWC)\n",
    "Final_ch = Lane_Detect(image_ch)\n",
    "plt.imsave('test_images_output/challenge.png',Final_ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set threshold to decide if the lane should be add to memory\n",
    "MAXIMUM_SLOPE_DIFF = 0.1\n",
    "MAXIMUM_INTERCEPT_DIFF = 50.0\n",
    "\n",
    "class LaneDetectWithMemo:\n",
    "    def __init__(self):\n",
    "        self.left_lane_que = create_lane_list()\n",
    "        self.right_lane_que = create_lane_list()\n",
    "        \n",
    "    def LanePipe(self,image):\n",
    "        \n",
    "        image_hsl = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "        image_yellow = isolate_yellow_hsl(image_hsl)\n",
    "        image_white = isolate_white_hsl(image_hsl)\n",
    "        # Combine white parts and yellow parts in a single pic\n",
    "        image_wy = cv2.bitwise_or(image_yellow,image_white)\n",
    "        # Combine yellow and white masks and original picture to derive the parts we are interested.\n",
    "        # This would reduce the noise and improve the performance if there is shadow on the ground.\n",
    "        image_com = cv2.bitwise_and(image,image,mask=image_wy)\n",
    "        image_gray = grayscale(image_com)\n",
    "        # Smoothing the image\n",
    "        kernal_size = 11\n",
    "        blur_image = cv2.GaussianBlur(image_gray,(kernal_size,kernal_size),0)\n",
    "        # Setup Canny\n",
    "        low_threshold = 10\n",
    "        high_threshold = 150\n",
    "        edges_image = cv2.Canny(blur_image,low_threshold,high_threshold)\n",
    "        # Define range of interest\n",
    "        masked_image = region_of_interest(edges_image) \n",
    "        bland_image, houghLines= hough_lines(masked_image, 1, np.pi/180, 1, 5, 1)\n",
    "        xl,yl,xr,yr = find_hough_lines(bland_image,houghLines)\n",
    "        slope_l, intercept_l = linear_regression_left(xl,yl)\n",
    "        slope_r, intercept_r = linear_regression_right(xr,yr)\n",
    "        # If the lane diverges too much, then use the mean value in memory to draw the lane\n",
    "        # If the lane is within thershold, then add it to memory and recalculate the mean value\n",
    "        if len(self.left_lane_que) == 0 and len(self.right_lane_que) == 0:\n",
    "            self.left_lane_que = left_lane_add(self.left_lane_que, slope_l, intercept_l)\n",
    "            self.right_lane_que = right_lane_add(self.right_lane_que, slope_r, intercept_r)\n",
    "            slope_l_mean, intercept_l_mean = left_lane_mean(self.left_lane_que)\n",
    "            slope_r_mean, intercept_r_mean = right_lane_mean(self.right_lane_que)\n",
    "        else:\n",
    "            slope_l_mean, intercept_l_mean = left_lane_mean(self.left_lane_que)\n",
    "            slope_r_mean, intercept_r_mean = right_lane_mean(self.right_lane_que)\n",
    "            slope_l_diff = abs(slope_l-slope_l_mean)\n",
    "            intercept_l_diff = abs(intercept_l-intercept_l_mean)\n",
    "            slope_r_diff = abs(slope_r-slope_r_mean)\n",
    "            intercept_r_diff = abs(intercept_r-intercept_r_mean)\n",
    "            if intercept_l_diff < MAXIMUM_INTERCEPT_DIFF and slope_l_diff < MAXIMUM_SLOPE_DIFF:\n",
    "                self.left_lane_que = left_lane_add(self.left_lane_que, slope_l, intercept_l)\n",
    "                slope_l_mean, intercept_l_mean = left_lane_mean(self.left_lane_que)\n",
    "            if intercept_r_diff < MAXIMUM_INTERCEPT_DIFF and slope_r_diff < MAXIMUM_SLOPE_DIFF:\n",
    "                self.right_lane_que = right_lane_add(self.right_lane_que, slope_r, intercept_r)\n",
    "                slope_r_mean, intercept_r_mean = right_lane_mean(self.right_lane_que)\n",
    "                \n",
    "        \n",
    "        hough_image = draw_lines(bland_image, intercept_l_mean, slope_l_mean,intercept_r_mean, slope_r_mean, xl, xr)\n",
    "        Final_image = weighted_img(hough_image,image)\n",
    "        \n",
    "        return Final_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/solidWhiteRight.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidWhiteRight.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:11<00:00, 19.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidWhiteRight.mp4 \n",
      "\n",
      "CPU times: user 29.8 s, sys: 673 ms, total: 30.5 s\n",
      "Wall time: 12 s\n"
     ]
    }
   ],
   "source": [
    "# Test on the first vedio, with solid white lane on the right\n",
    "LaneDetect_1 = LaneDetectWithMemo()\n",
    "white_output = 'test_videos_output/solidWhiteRight.mp4'\n",
    "clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(LaneDetect_1.LanePipe) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidWhiteRight.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/solidYellowLeft.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidYellowLeft.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 681/682 [00:36<00:00, 18.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidYellowLeft.mp4 \n",
      "\n",
      "CPU times: user 1min 41s, sys: 2.42 s, total: 1min 44s\n",
      "Wall time: 37 s\n"
     ]
    }
   ],
   "source": [
    "# Now for the one with the solid yellow lane on the left. This one's more tricky!\n",
    "LaneDetect_2 = LaneDetectWithMemo()\n",
    "yellow_output = 'test_videos_output/solidYellowLeft.mp4'\n",
    "clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(LaneDetect_2.LanePipe)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidYellowLeft.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Optional Challenge\n",
    "\n",
    "This vedio has curved lane and shadow on the ground. In the futrue I would use polynomial to represent the lane instead of a single line. The shadow is improved by extracting yellow and white in the picture and combine them with the original image, which represent the parts we are interested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/challenge.mp4\n",
      "[MoviePy] Writing video test_videos_output/challenge.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [00:22<00:00, 11.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/challenge.mp4 \n",
      "\n",
      "CPU times: user 54.5 s, sys: 1.62 s, total: 56.2 s\n",
      "Wall time: 24 s\n"
     ]
    }
   ],
   "source": [
    "LaneDetect_ch = LaneDetectWithMemo()\n",
    "challenge_output = 'test_videos_output/challenge.mp4'\n",
    "clip3 = VideoFileClip('test_videos/challenge.mp4')\n",
    "challenge_clip = clip3.fl_image(LaneDetect_ch.LanePipe)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/challenge.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
